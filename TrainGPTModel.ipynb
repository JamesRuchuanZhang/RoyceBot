{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU For Free \n",
        "\n",
        "by [Max Woolf](http://minimaxir.com)\n",
        "\n",
        "*Last updated: November 10th, 2019*\n",
        "\n",
        "Retrain an advanced text generating neural network on any text dataset **for free on a GPU using Collaboratory** using `gpt-2-simple`!\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple). You can also read my [blog post](https://minimaxir.com/2019/09/howto-gpt2/) for more information how to use this notebook!\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "outputId": "00990a3b-b0a0-496f-f044-d80ef16f0cd4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 1.x selected.\n",
            "  Building wheel for gpt-2-simple (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bj2IJLHP3KwE"
      },
      "source": [
        "## GPU\n",
        "\n",
        "Colaboratory uses either a Nvidia T4 GPU or an Nvidia K80 GPU. The T4 is slightly faster than the old K80 for training GPT-2, and has more memory allowing you to train the larger GPT-2 models and generate more text.\n",
        "\n",
        "You can verify which GPU is active by running the cell below."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUmTooTW3osf",
        "outputId": "c402457f-ddbe-4b2a-c940-cf495ebf3ef2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Jun  3 15:29:29 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 440.82       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   33C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                       GPU Memory |\n",
            "|  GPU       PID   Type   Process name                             Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "* `1558M`: the \"extra large\", true model. Will not work if a K80 GPU is attached to the notebook. (like `774M`, it cannot be finetuned).\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "outputId": "15a56a5c-e086-4bfe-f2f1-a6f2ed92772a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 254Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 56.8Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 309Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 177Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 526Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 91.0Mit/s]                                                \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 123Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "outputId": "0bb84c16-601c-4ccb-acd5-453bb667170d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll"
      },
      "source": [
        "file_name = \"RoycePostsMaster.txt\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS"
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "outputId": "ded6d7bd-5c3b-41c7-961a-7cd3fc7d7a13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 1/1 [00:01<00:00,  1.87s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 305645 tokens\n",
            "Training...\n",
            "[10 | 51.41] loss=2.28 avg=2.28\n",
            "[20 | 94.24] loss=2.61 avg=2.45\n",
            "[30 | 137.70] loss=2.11 avg=2.33\n",
            "[40 | 181.96] loss=2.67 avg=2.42\n",
            "[50 | 225.76] loss=2.30 avg=2.39\n",
            "[60 | 269.21] loss=1.77 avg=2.29\n",
            "[70 | 312.08] loss=2.65 avg=2.34\n",
            "[80 | 355.27] loss=2.18 avg=2.32\n",
            "[90 | 398.38] loss=2.47 avg=2.34\n",
            "[100 | 442.75] loss=1.75 avg=2.28\n",
            "[110 | 486.41] loss=2.36 avg=2.29\n",
            "[120 | 530.06] loss=3.07 avg=2.35\n",
            "[130 | 572.81] loss=1.94 avg=2.32\n",
            "[140 | 616.01] loss=2.36 avg=2.32\n",
            "[150 | 659.07] loss=2.26 avg=2.32\n",
            "[160 | 703.31] loss=1.66 avg=2.27\n",
            "[170 | 746.88] loss=2.39 avg=2.28\n",
            "[180 | 791.03] loss=2.31 avg=2.28\n",
            "[190 | 834.21] loss=2.26 avg=2.28\n",
            "[200 | 877.20] loss=2.39 avg=2.29\n",
            "======== SAMPLE 1 ========\n",
            " rite like it's OK to be gay\n",
            "so uhh\n",
            "hmm\n",
            ":fearful:\n",
            ":fearful:\n",
            "it's ok\n",
            "no we don't want to start afaik\n",
            ":ANGRYCRY:\n",
            "just wait u rite\n",
            "@Tsubaki u like\n",
            "wth ur not\n",
            ":grimacing:\n",
            "lul\n",
            ":coolranch:\n",
            ":blobsweats:\n",
            ":fearful:\n",
            ":fearful:\n",
            ":jimgasm:\n",
            "it's ok we want to save face\n",
            "lul\n",
            "fk off\n",
            ":grimacing:\n",
            ":weary:\n",
            ":joy:\n",
            "lul\n",
            ":fearful:\n",
            "wtf\n",
            "we gottin our wtf\n",
            "fk off\n",
            "wth\n",
            ":blobsweats:\n",
            "cmon man\n",
            "hmm\n",
            "this fkin summer\n",
            "wth i gotta watch lmao\n",
            "aight\n",
            "is the show ready wth\n",
            "i need to make it to summer\n",
            "i think the series is out today\n",
            "winking\n",
            ":joy:\n",
            ":fearful:\n",
            "is that a movie\n",
            ":fearful:\n",
            "woke up i did\n",
            "wow i'm the only one that didn't fuck up\n",
            ":ANGRYCRY:\n",
            "huh\n",
            "if idk what that shit is i think it's a movie\n",
            "huh\n",
            ":OHnoMyGOD:\n",
            "it's worth it but then idk if i want to do it again if i want\n",
            "i think it's kinda retarded to just have me watch it again\n",
            ":grimacing:\n",
            ":sugoi:\n",
            "wth\n",
            "how long is it?\n",
            "lul\n",
            "wth\n",
            "wait a minute\n",
            "a year\n",
            "s3 at least\n",
            ":uhoh:\n",
            ":blobsweats:\n",
            "wow\n",
            "lotta kinks to ironmen to make sure they can work them out\n",
            ":ANGRYCRY:\n",
            ":fearful:\n",
            ":blobsweats:\n",
            "what is it?\n",
            "i mean\n",
            "what is that\n",
            "i might be wrong\n",
            "oh\n",
            "this is what it's like to be gay\n",
            "i'm gay\n",
            "i like cuck\n",
            ":blobsweats:\n",
            "i guess uci l o l\n",
            ":ANGRYCRY:\n",
            ":rilakkumasweats:\n",
            "i like him so far :blobsweats:\n",
            "uhh\n",
            ":rilakkumasweats: :blobsweats:\n",
            "i think this guy is like\n",
            "anxious_face_with_sweat_droplets\n",
            "wait\n",
            "so i ask rn idk if he's gay\n",
            "@Jiufu are you still at the store\n",
            "idk man\n",
            "i think that place is pretty fkin cool\n",
            "uh oh\n",
            "idk idk what it is\n",
            "ohhhh\n",
            "was that the one with the kantai shirt\n",
            "i think\n",
            ":father:\n",
            "the one with the shirt is like\n",
            "the one uhh\n",
            "wut\n",
            "idk a whole lot about that one\n",
            "it's just\n",
            "i think he likes hinobutani\n",
            "and that's fine with me\n",
            "yeah man\n",
            "i might not be gay\n",
            "but that's how it is right\n",
            ":fearful:\n",
            ":joy:\n",
            "ur gonna be ok man\n",
            ":fearful:\n",
            ":FONT:\n",
            ":grimacing:\n",
            ":fearful: OK_hand\n",
            ":father:\n",
            "what is that\n",
            "wait is she gay\n",
            ":fearful:\n",
            ":ANGRYCRY:\n",
            "it's ok lmao\n",
            "oh yeah\n",
            "is that her voice\n",
            "idk if that's her voice but\n",
            ":grimacing:\n",
            ":fearful:\n",
            "that's how it is\n",
            "idk if it's right\n",
            ":fearful:\n",
            "i think it's ok\n",
            ":fearful:\n",
            "that's why we go\n",
            "not that i was saying that\n",
            "wait\n",
            "do you have her #giraffle\n",
            ":fearful:\n",
            "did you get a giver key?\n",
            ":rilakkumasweats:\n",
            ":grimacing: :fearful:\n",
            "fk\n",
            "i don't remember how to set it up\n",
            ":blobsweats:\n",
            "how was that?\n",
            "lul idk on how to set it up\n",
            "the first question was like\n",
            "how\n",
            "how did you make it\n",
            ":joy:\n",
            ":blobsweats:\n",
            "ya ur a good #girl\n",
            "she's cute af\n",
            "lmk\n",
            ":AyaWOW: :blobsweats:\n",
            ":father: :father:\n",
            ":father: :Father: :father:\n",
            ":father: :father:\n",
            "wait\n",
            "where are we now?? hahaha\n",
            "wtf\n",
            "is it a r umi niseboi\n",
            "uhh\n",
            "is this all a meme\n",
            ":father:\n",
            ":father: :father:\n",
            "\n",
            "\n",
            "[210 | 940.05] loss=2.01 avg=2.27\n",
            "[220 | 984.13] loss=2.53 avg=2.29\n",
            "[230 | 1027.77] loss=2.10 avg=2.28\n",
            "[240 | 1071.82] loss=2.25 avg=2.27\n",
            "[250 | 1115.15] loss=2.33 avg=2.28\n",
            "[260 | 1157.98] loss=1.53 avg=2.24\n",
            "[270 | 1201.17] loss=2.41 avg=2.25\n",
            "[280 | 1244.24] loss=2.11 avg=2.25\n",
            "[290 | 1288.59] loss=2.47 avg=2.25\n",
            "[300 | 1332.13] loss=1.37 avg=2.22\n",
            "[310 | 1375.99] loss=1.64 avg=2.20\n",
            "[320 | 1418.80] loss=1.65 avg=2.18\n",
            "[330 | 1461.86] loss=2.14 avg=2.18\n",
            "[340 | 1504.91] loss=1.76 avg=2.16\n",
            "[350 | 1548.72] loss=1.31 avg=2.13\n",
            "[360 | 1592.39] loss=1.61 avg=2.12\n",
            "[370 | 1636.18] loss=1.47 avg=2.10\n",
            "[380 | 1679.11] loss=2.05 avg=2.09\n",
            "[390 | 1722.14] loss=1.28 avg=2.07\n",
            "[400 | 1765.24] loss=1.47 avg=2.05\n",
            "======== SAMPLE 1 ========\n",
            "::daBOiindaMrrr:\n",
            ":wakawakawakawakawak:\n",
            "it's because you're not doing initialization\n",
            "and that means your call to square brackets will usually be square brackets\n",
            "so it'll cause your square brackets call to go out the left y axis too\n",
            "cause it's wrong in my experience when i turn my volume up and down when i'm doing initialization\n",
            "idk why but i've heard it seems dumb since the initialization isn't working out of the way it's looking\n",
            "then you have to do square brackets every time\n",
            "and for some other reason initialization doesn't work for everything\n",
            "oh i guess you have to do square brackets everyday except when you need a scapegoat or something\n",
            "ya\n",
            "it's not weird at all\n",
            "wth u dont wanna rip off ur self i know u guys want to rk u\n",
            "ya it's pb since it's ucla based hahaha\n",
            ":rilakkumasweats:\n",
            ":fearful:\n",
            ":father:\n",
            ":fearful: :fearful:\n",
            ":fearful:\n",
            "just drop all those hours into a habit and shit hit the fan hahahaha\n",
            ":joy:\n",
            "uhh\n",
            "it's true hahaha???\n",
            "i think uci is a religion l 0 l\n",
            "holy it looks like it's failing rn tho hahahahha\n",
            "oh wth u spent so much money\n",
            "they got broke :ANGRYCRY:\n",
            ":cold_face:\n",
            "i dont think university is that bad\n",
            "it probably just requires the like\n",
            "grad school\n",
            "or some shit that gets built like hell it ends u right\n",
            "deposting university is kinda weird because if you're doing some sort of research project in another country and you want to have an \"official\" institution for some reason then you usually need something there that's close to government or some shit cause u no wut i meen\n",
            "ok but there are government offices in murrieta though\n",
            "like murrieta lab or something\n",
            "if u dont wanna go to j u dk what is ur sht supposed to be cause i no wut i meen\n",
            "or u think of it more like\n",
            "fridays at 20\n",
            "yeah they dont matter\n",
            "it's like when christ christ christ christ christ christ\n",
            "the day after that is holy\n",
            ":fearful:\n",
            "oh shit i got that one\n",
            "wth\n",
            "ok here's the bad news\n",
            "i should have taken it back\n",
            ":fearful:\n",
            ":fearful:\n",
            "i know we talkin to fc about how cs is still fkin sht\n",
            "but it's not like they dont care\n",
            ":SaayaXD:\n",
            ":fearful:\n",
            "they might go\n",
            "except if they have to\n",
            "that's nach\n",
            "what the\n",
            "it's ok hahaha\n",
            ":AyaWOW: :AyaWOW:\n",
            "oh fuck they are still fkin sht af\n",
            "hahaha\n",
            ":fearful:\n",
            "the game is actually fun but idk man\n",
            ":fearful:\n",
            ":AyaWOW:\n",
            ":cold_face:\n",
            "ur adictd\n",
            "u adictd\n",
            ":fearfull:\n",
            "huh\n",
            "they can just call it quits imo\n",
            ":fearful:\n",
            "huh\n",
            ":thinkms:\n",
            "they dont care either\n",
            "he can't call it that\n",
            "huh\n",
            "imagine if i gave this game up\n",
            "it wasnt impossible\n",
            "i mean\n",
            "i dont think so\n",
            "oh\n",
            ":joy:\n",
            "you have to use joystick or mouse\n",
            "yeah\n",
            "i think you could just get an on then do the crafting l 0 l\n",
            "yeah\n",
            "which is easier if your character cant jump l 0 l\n",
            "i guess crafting is mostly aesthetic right\n",
            "that game has shit like dlc and shit\n",
            "uhh\n",
            "idk how to put this\n",
            ":joy_cat:\n",
            "i think you could do it if you didnt wanna kill em\n",
            "idk how to read an e page though\n",
            "it's too bad that game didnt have cheme for q10\n",
            "or at least cheme that game doesn't exist\n",
            "it's aight\n",
            "is that like\n",
            "liek i read a book, then i go through and cpp cheme stuff in q10\n",
            "i see a difference in eyes :grimacing:\n",
            "u no wut i mean\n",
            "u dont ever fail high cs tho do it right\n",
            ":fearful:\n",
            "idk if i can get those two done :grimacing:\n",
            "ur so close to breaking\n",
            "i cant tell\n",
            "since there's no way iguese r1\n",
            "actually i think igu se atleast\n",
            "it's ok\n",
            "if im not unlucky jim is right\n",
            "huh\n",
            "i think if you look at all the cs hatcheries in q110\n",
            "there are some that are pretty small\n",
            "but some that are pretty big\n",
            "that's\n",
            "\n",
            "[410 | 1826.10] loss=1.23 avg=2.03\n",
            "[420 | 1869.92] loss=1.67 avg=2.02\n",
            "[430 | 1913.81] loss=0.96 avg=1.99\n",
            "[440 | 1956.80] loss=1.30 avg=1.97\n",
            "[450 | 1999.81] loss=0.75 avg=1.93\n",
            "[460 | 2042.95] loss=1.94 avg=1.93\n",
            "[470 | 2086.43] loss=1.76 avg=1.93\n",
            "[480 | 2130.46] loss=1.36 avg=1.91\n",
            "[490 | 2174.24] loss=1.49 avg=1.90\n",
            "[500 | 2217.58] loss=0.75 avg=1.87\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 2263.77] loss=1.24 avg=1.86\n",
            "[520 | 2306.88] loss=1.57 avg=1.85\n",
            "[530 | 2350.27] loss=0.89 avg=1.83\n",
            "[540 | 2394.29] loss=1.24 avg=1.81\n",
            "[550 | 2437.87] loss=1.24 avg=1.80\n",
            "[560 | 2481.72] loss=0.96 avg=1.78\n",
            "[570 | 2524.48] loss=0.93 avg=1.76\n",
            "[580 | 2567.60] loss=0.76 avg=1.74\n",
            "[590 | 2610.84] loss=0.79 avg=1.72\n",
            "[600 | 2654.86] loss=0.66 avg=1.69\n",
            "======== SAMPLE 1 ========\n",
            " is one of the most important; getting those two items before level restriction is too big of a steep learning curve.\n",
            "is it possible to get both\n",
            "i feel like i'd need a level doubly linked list\n",
            "since it's doing that already if you know what you're doing\n",
            "and they're linked\n",
            ":fearful:\n",
            "what if you know you're actually doing the linking\n",
            "how do you know\n",
            "an nbd\n",
            "yeah those two are BAD\n",
            "it might be a relic\n",
            "yeah technically can be\n",
            "they're linked, but yeah\n",
            "the thing you need to know\n",
            "the nbd is kinda hard\n",
            "it takes too long  to walk down it\n",
            "huh\n",
            "yeah\n",
            "how do you know ya'll hashed?\n",
            "i feel like i can assume it for you :fearful:\n",
            "it must have worked in a while, i swear\n",
            "ok >>3\n",
            "xd\n",
            "yeah same, but >>3 is a little more verbose\n",
            "i should just og on average\n",
            "i wanna try to put an average iense too\n",
            "that might take me a while\n",
            "hahaha\n",
            ":daBOiindaMrrr:\n",
            "im tryin to level cs and not hjaljamajo\n",
            ":OHnoMyGOD:\n",
            "nauseated_face\n",
            "yeah that's kinda what i mean\n",
            ":rilakkumasweats:\n",
            "i started work at Kew a long time ago so i should be able to \"waste\" time idk what was goin on in their heads. :fearful:\n",
            "lmao\n",
            "ok me too i guess :thinkms:\n",
            "what is this heap\n",
            "what is the size of\n",
            "i guess it can't be worse than the std::max size\n",
            ":ANGRYCRY:\n",
            ":rilakkumasweats:\n",
            "why is that rng 848\n",
            "why even have?\n",
            "max of 69999??\n",
            ":daBOiindaMrrr:\n",
            "wtf hfl sent me a message saying they were rescinding\n",
            "yup\n",
            "they have to make the plane drop post something or some shit because people got confused when heading to Australia\n",
            ":daBOiindaMrrr:\n",
            "wtf is going on here\n",
            ":blobhyperthinksweat:\n",
            "i guess i'm royally hurt?\n",
            ":joy:\n",
            "damn i might be homeless for a while\n",
            ":daBOiindaMrrr:\n",
            ":joy:\n",
            "i was going to say something but i didn't wanna go as planned\n",
            ":SaayaXD:\n",
            "if i was in japan i'd take a closer look\n",
            "is that an out\n",
            "get in there\n",
            ":blobsweats:\n",
            "yikes\n",
            "hmm\n",
            "uhhh\n",
            "it should be there by now right?\n",
            "how much are these stuffs\n",
            "if it's in there i can at least assume it's safe\n",
            "ok i haven't checked already hahahaha\n",
            ":blobsweats:\n",
            "nah it should be there probably\n",
            "idk if that's correct\n",
            "should probably check discord too\n",
            ":daBOiindaMrrr:\n",
            "just look in the schools\n",
            "christ you can't just find china schools rn\n",
            "christ that's just one hit on everyone\n",
            ":father:\n",
            ":OHnoMyGOD:\n",
            "get in there\n",
            ":daBOiindaMrrr: :daBOiindaMrrr:\n",
            ":blobsweats: :blobhyperthinksweat: :blobhyperthinksweat: :blobhyperthinksweat: :blobhyperthinksweat:\n",
            ":thinkms:\n",
            "oh like kimi no na wa or sumire?\n",
            "i started yt search\n",
            "and i see sumire is the number one favorite\n",
            ":thinkms:\n",
            ":ANGRYCRY:\n",
            "wth\n",
            "im jokin old it's hard to say no\n",
            ":thinkms:\n",
            "fk\n",
            ":thinkms:\n",
            ":thinkms:\n",
            ":thinkms:\n",
            "get me one of these\n",
            ":blobsweats:\n",
            ":joy: :ANGRYCRY: :blobsweats:\n",
            "huh???\n",
            "i cant remember the last time i posted this\n",
            "das wut im talkin about\n",
            ":thinkms:\n",
            "wtf u cant bait me\n",
            "how many of my posters are up for yh\n",
            "yikes\n",
            ":blobsweats:\n",
            "fk\n",
            "i wanna go to asano wtf\n",
            ":blobhyperthinksweat:\n",
            ":blobhyperthinksweat:\n",
            "how much is 123\n",
            ":thinkms:\n",
            "oof\n",
            ":blobhyperthinksweat:\n",
            "123 is rock solid\n",
            ":blobhyperthinksweat:\n",
            "damn i hardly go to grad\n",
            "actually\n",
            "maybe it's just me but i'm not good enough\n",
            "i can't decide if it's a good idea next quarter\n",
            ":blobhyperth\n",
            "\n",
            "[610 | 2716.41] loss=0.60 avg=1.67\n",
            "[620 | 2759.32] loss=1.32 avg=1.66\n",
            "[630 | 2802.34] loss=0.75 avg=1.64\n",
            "[640 | 2845.46] loss=0.71 avg=1.62\n",
            "[650 | 2889.15] loss=0.44 avg=1.60\n",
            "[660 | 2932.87] loss=1.04 avg=1.59\n",
            "[670 | 2976.60] loss=0.83 avg=1.57\n",
            "[680 | 3020.00] loss=0.78 avg=1.56\n",
            "[690 | 3062.81] loss=0.84 avg=1.54\n",
            "[700 | 3106.03] loss=1.05 avg=1.53\n",
            "[710 | 3149.34] loss=0.33 avg=1.51\n",
            "[720 | 3193.49] loss=0.41 avg=1.49\n",
            "[730 | 3237.28] loss=0.53 avg=1.47\n",
            "[740 | 3280.84] loss=0.97 avg=1.46\n",
            "[750 | 3323.66] loss=0.71 avg=1.45\n",
            "[760 | 3366.82] loss=0.48 avg=1.43\n",
            "[770 | 3409.89] loss=0.43 avg=1.41\n",
            "[780 | 3454.05] loss=0.64 avg=1.39\n",
            "[790 | 3497.76] loss=0.48 avg=1.38\n",
            "[800 | 3541.29] loss=0.33 avg=1.36\n",
            "======== SAMPLE 1 ========\n",
            "_safebooru yamashiro\n",
            ".safebooru yamashiro\n",
            ":joy:\n",
            ":uhoh:\n",
            ">jisho 通色弗\n",
            ":joy:\n",
            ">jisho 通色弗\n",
            ":uhoh:\n",
            ">jisho 時雨\n",
            ":joy:\n",
            ":uhoh:\n",
            ">jisho 少子高齢加\n",
            ">jisho 彩弟始\n",
            ">jisho 體\n",
            ">jisho 體\n",
            "angry_face\n",
            "@S2VX @everyone i want to blow pasting some girls so i can see cute ones rn\n",
            "HAHAHA\n",
            "wtf\n",
            "get me one of these\n",
            ":coolpizza:\n",
            ":uhoh:\n",
            ":you:\n",
            ":fearful:\n",
            ":howdy:\n",
            ":ANGRYCRY:\n",
            "pastel is pretty jank, even by modern standards\n",
            "or not\n",
            "it's just ok\n",
            "the hair is so base\n",
            "i ended it off\n",
            "i wouldn't get that bob\n",
            "face_with_steam_from_nose\n",
            "what kind of music does it have\n",
            "what the fk\n",
            "what the fk\n",
            "if anyone wants to come by lia is jinx it's me\n",
            "no its lil loli\n",
            "u ever giv me one\n",
            "maybe i can p mean shit\n",
            "for now i'm going to fkin scam everyone\n",
            "who's gettin shokyoudta\n",
            "and the meeting place is a lolita\n",
            "so if you're wanting to go to aschilalia though\n",
            "that's t00 again\n",
            "smarter than kochi??\n",
            "yeah\n",
            "hahaha\n",
            "the meeting place is plain old kochi\n",
            "basically a bath house with shower and comfyr seats\n",
            "aight can we get a job for that\n",
            "lmao\n",
            "ya it wouldty\n",
            "is that the size of a good company job\n",
            ":joy:\n",
            "ya\n",
            "small staff :joy:\n",
            "small release, but no big ones :joy:\n",
            "i only saw one little thing :joy:\n",
            ":joy:\n",
            "cmon dude\n",
            "plz\n",
            "tidy me\n",
            "i don't wanna look in the eye of the social media disaster\n",
            "ya if you can afford it\n",
            "wait is there an internship at kochi so i better make that happen\n",
            ":bend_hand\n",
            "ok\n",
            ":joy:\n",
            "i luv it\n",
            "ya\n",
            "max is completely mainstream in appearance\n",
            "and if you look at past performance he's fkin gwo\n",
            ":grimacing:\n",
            "ya das all\n",
            "kongou is a biggie\n",
            "ya it casts a shadow over society\n",
            "hella life im 14 or something\n",
            "ur fkin psychologying sht up\n",
            ":blobhyperthinksweat:\n",
            "u no no wut im sayin\n",
            ":umithinking:\n",
            ":blobhyperthinksweat:\n",
            "waste of time and effort\n",
            ":blobhyperthinksweat:\n",
            "just wear smartfashy\n",
            "and shawl. Right hand click shoes with eye shadow on some of them. Weird combo dude. LUV it. 00 87 90 90 90.\n",
            "woozy\n",
            ":blobhyperthinksweat:\n",
            ":joy:\n",
            ":joy:\n",
            "it doesn't have to be true\n",
            "i am looking for it wutimu says\n",
            "ayyy\n",
            "that too\n",
            "thinking_face\n",
            "there are times where i would rather kill people than find out about mermaids\n",
            ":joy: pistol\n",
            "@S2VX dead and wrong\n",
            ":umithinking:\n",
            "yeah there are multiple uhh\n",
            "ass things\n",
            "there must be a nsfw channel name\n",
            "that is but idk it\n",
            ":joy:\n",
            "@S2VX here\n",
            "@Jims http://tokyudice.range.au/i/\n",
            "@no. was that uhh real\n",
            "uhh\n",
            "i hav no excuse other than umi\n",
            ":joy:\n",
            "cmon man that's cute\n",
            "that's the only bad thing about umi\n",
            "ever\n",
            "can't marry her :joy:\n",
            "literal equivalent to a class of work that pays her tuition\n",
            "lmao\n",
            ":joy:\n",
            "idk about that one dog\n",
            ":joy:\n",
            "i only wish that had happened a couple years ago\n",
            "ohhh\n",
            "that was pretty bad\n",
            "i no wut ur sayin\n",
            "wth\n",
            "get back in there\n",
            "FK\n",
            "i no wut ur sayin so\n",
            "hey @Jims how long have u been failin the class you wanted to take?\n",
            "or have taken it already?\n",
            "i feel like i shilling for that class\n",
            "hey it came easy on uhh\n",
            "oh i can get rich quick though\n",
            "take a middle school nothin get in until 2020\n",
            ":joy:\n",
            "oh and they lower the\n",
            "\n",
            "[810 | 3601.69] loss=0.44 avg=1.34\n",
            "[820 | 3644.84] loss=0.35 avg=1.32\n",
            "[830 | 3688.59] loss=0.32 avg=1.31\n",
            "[840 | 3732.46] loss=0.44 avg=1.29\n",
            "[850 | 3776.61] loss=0.40 avg=1.28\n",
            "[860 | 3819.83] loss=0.47 avg=1.26\n",
            "[870 | 3862.84] loss=0.50 avg=1.25\n",
            "[880 | 3906.00] loss=0.40 avg=1.23\n",
            "[890 | 3949.52] loss=0.39 avg=1.22\n",
            "[900 | 3993.53] loss=0.41 avg=1.21\n",
            "[910 | 4037.40] loss=0.38 avg=1.19\n",
            "[920 | 4080.55] loss=0.33 avg=1.18\n",
            "[930 | 4123.48] loss=0.33 avg=1.16\n",
            "[940 | 4166.67] loss=0.28 avg=1.15\n",
            "[950 | 4210.28] loss=0.18 avg=1.13\n",
            "[960 | 4254.29] loss=0.32 avg=1.12\n",
            "[970 | 4298.08] loss=0.24 avg=1.11\n",
            "[980 | 4341.91] loss=0.25 avg=1.09\n",
            "[990 | 4384.65] loss=0.22 avg=1.08\n",
            "[1000 | 4427.76] loss=0.21 avg=1.07\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /tensorflow-1.15.2/python3.6/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3"
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD"
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "outputId": "689a0e00-3170-4006-ce0c-0cdfb64df2d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading checkpoint checkpoint/run1/model-1000\n",
            "INFO:tensorflow:Restoring parameters from checkpoint/run1/model-1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "outputId": "da3b9ceb-edcf-4861-eda4-14c52464c8fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "uhh\n",
            ":weary:\n",
            "is that the wrong of debian\n",
            "you're using ubuntu lmao\n",
            "cat_face_with_smiling_eyes\n",
            "@Harrharrqi hey brenn dont just buy into it think about the long term\n",
            "think about the long term\n",
            "what do you mean about what ubuntu means right\n",
            "what is aarch64?\n",
            "hell\n",
            "oh\n",
            "what do you mean about binary linking\n",
            "llvm\n",
            "do you mean linking on the go with cpp?\n",
            "yeah i would\n",
            "what is aarch64?\n",
            "i was thinking it's almost that but at the cost of compiling the environment\n",
            "so\n",
            "what do you mean when you say \"compile and run\"\n",
            "yeah i mean compile and run\n",
            "yeah it can fail\n",
            "off the top of my head, it says do so\n",
            "how does it compile?\n",
            "oh\n",
            "what happens once it's run?\n",
            "it downloads the cpp source\n",
            "i don't know what it does with the cpp.osu that has cpp, but i can't say for sure\n",
            "lmao that sucks\n",
            "i don't think it's a bad idea if you've already compiled your own source yourself\n",
            "otherwise you cant say \"yeah this is what I want to do\"\n",
            "oh it gets shut down\n",
            "i don't like it when windows gets shut down l0l\n",
            "yeah it's nice\n",
            "you don't have to worry about it since it doesn't matter\n",
            "ubuntu gets a lot of attention so i don't think it's that bad\n",
            "hey that reminds me\n",
            "free up some money for my wife\n",
            ":grimacing:\n",
            "yeah just keep buying and getting more\n",
            ":ANGRYCRY:\n",
            "unless you wanna try hard and get back into the r1 rn\n",
            "uhh\n",
            "wait really\n",
            "did you actually\n",
            "????\n",
            "oh children of grape and me\n",
            "i was just thinking it's like\n",
            "a fkin god for shutting down my computer\n",
            "i now see that i'm a country girl\n",
            "ya go for it\n",
            ":fearful:\n",
            "wtf no\n",
            "never\n",
            "i just shut down my computer\n",
            "except emailing stuff\n",
            "down to three files at a time\n",
            "and then windows explorer\n",
            "and grabbing all those gigabytes of data so you can play the games you want\n",
            "yeah that's pretty bad\n",
            "comparing to playing only online games though\n",
            "sounds hella fun\n",
            "xd\n",
            "wait actually\n",
            "did you actually just say that right\n",
            "wtf\n",
            "i dont play fighting game\n",
            "but chess\n",
            "y did you even play fighting game at home when you were just casually playing\n",
            "i play fighting game at school\n",
            "uhh\n",
            "that's actually pretty cool\n",
            "the guys at gf's table talk a lot about how the emphasis is on getting better at it\n",
            "so it's kinda like chess on steroids\n",
            "l o l\n",
            "im maxing out the cs and mmu club member ones\n",
            "sorry man i just told you about that\n",
            "it's sooo good\n",
            "i think a lot of it is cultural/current/whatever\n",
            "the thing is, I actually don't really like fighting games if you're not used to it :fearful:\n",
            "i played maij weird for a week then moved on\n",
            ":fearful:\n",
            "nothing wrong here cmon man\n",
            "aha\n",
            "no shit i haven't been here too\n",
            "this is for one\n",
            ":joy:\n",
            "holy\n",
            "yeah that's it\n",
            "holy\n",
            "wait\n",
            "is it doin the same with this one?\n",
            "yo that rhyme\n",
            "is kinda weird\n",
            "i feel like the second verse is more melodica\n",
            "ahhh fuck\n",
            "friday nekkii\n",
            "idk what's goin on here\n",
            "but i know that there's somethin wrong with this song\n",
            "oh yikes\n",
            "that wasdflkdjhkerdjhs\n",
            "fuck\n",
            ">90%\n",
            "assassinating jimmy\n",
            "while looking for trouble\n",
            ":fearful:\n",
            "and that's all the band members talkative\n",
            ":ANGRYCRY:\n",
            "kaempii\n",
            ":joy:\n",
            "kaempii\n",
            ":sugoi:\n",
            "lmao\n",
            "flattrope\n",
            "i've listened to aa before\n",
            ":fearful:\n",
            "mania xo\n",
            ":umithinking:\n",
            "kirara idol\n",
            ":blobsweats:\n",
            "is that the one with the big ol suomi\n",
            "oh they did that too\n",
            "but this one\n",
            "oh they had the Lawson fang\n",
            "that's another story\n",
            "carls' jr\n",
            "they're just so fuckin cool\n",
            "WAIT HOLKD UP\n",
            "IS THAT SAKURA AYANE\n",
            "wait this one is called 'The Girl'\n",
            "i forgot\n",
            "is that the right shape\n",
            "so the cannonball wing is where the flying fox is supposed to be\n",
            "oh the bird vs the bear meme\n",
            "wow that one is a lil\n",
            ":fearful:\n",
            "wait\n",
            "u r s'peach\n",
            "me\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "outputId": "45522f88-8da4-49fb-8d21-5c8b5f3a38ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "newText = gpt2.generate(sess,\n",
        "              length=15,\n",
        "              temperature=0.8,\n",
        "              prefix=\"what the fuck\",\n",
        "              nsamples=1,\n",
        "              batch_size=1,\n",
        "              #truncate = '\\n',\n",
        "              include_prefix = False\n",
        "              )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "what the fuck\n",
            "wth\n",
            "i've been playing cs for like a year now\n",
            "\n",
            "<class 'str'>\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0"
      },
      "source": [
        "gen_file = 'gpt2_gentext_test.txt'\n",
        "\n",
        "newText = gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      length=15,\n",
        "                      temperature=0.7,\n",
        "                      prefix = \"How are you\",\n",
        "                      nsamples=1,\n",
        "                      batch_size=1,\n",
        "                      truncate = '\\n',\n",
        "                      include_prefix = False\n",
        "                      )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJ1zjmeWFyJO",
        "outputId": "23d11d6d-1977-43be-a2e7-8fa502b4812b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "with open('gpt2_gentext_test.txt', encoding = 'utf8') as f:\n",
        "  lines = f.readlines()\n",
        "print(lines[1:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-7680a2489fe7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'gpt2_gentext_test.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'rstrip'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g"
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M or 1558M models with this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX"
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}